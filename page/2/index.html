<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/panda-180-3.jpg">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/panda-32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/panda-16.png">
  <link rel="mask-icon" href="/images/panda.svg" color="#222">
  <meta name="baidu-site-verification" content="m1ei8mEvXD">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"mxxct4git.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="君子不器">
<meta property="og:type" content="website">
<meta property="og:title" content="猫熊小才天の书院">
<meta property="og:url" content="https://mxxct4git.github.io/page/2/index.html">
<meta property="og:site_name" content="猫熊小才天の书院">
<meta property="og:description" content="君子不器">
<meta property="og:locale">
<meta property="article:author" content="Mxxct">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://mxxct4git.github.io/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-Hans'
  };
</script>

  <title>猫熊小才天の书院</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">猫熊小才天の书院</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://mxxct4git.github.io/2020/10/26/HBase-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/panda-180.png">
      <meta itemprop="name" content="Mxxct">
      <meta itemprop="description" content="君子不器">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="猫熊小才天の书院">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/10/26/HBase-2/" class="post-title-link" itemprop="url">HBase进阶</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-10-26 15:43:00" itemprop="dateCreated datePublished" datetime="2020-10-26T15:43:00+08:00">2020-10-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-19 20:46:22" itemprop="dateModified" datetime="2021-01-19T20:46:22+08:00">2021-01-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/HBase/" itemprop="url" rel="index"><span itemprop="name">HBase</span></a>
                </span>
            </span>

          
            <span id="/2020/10/26/HBase-2/" class="post-meta-item leancloud_visitors" data-flag-title="HBase进阶" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/10/26/HBase-2/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/10/26/HBase-2/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="HBase进阶"><a href="#HBase进阶" class="headerlink" title="HBase进阶"></a>HBase进阶</h2><p><a href="http://hbasefly.com/2017/07/02/hbase-sequenceid/">HBase中的HLog</a><br><a href="http://hbasefly.com/2019/10/18/hbase-memstore-evolution/">HBase中的MemStore</a></p>
<h3 id="1-架构"><a href="#1-架构" class="headerlink" title="1. 架构"></a>1. 架构</h3><p><img src="https://images.weserv.nl/?url=https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180402125111282-1966599087.png" alt="架构图"></p>
<p><img src="https://images.weserv.nl/?url=https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180402130346713-706113248.png" alt="物理存储"></p>
<p>master负责管理多个region server，一个region server里有多个region。<br>一个表会划分多个region，起初只有一个，数据增多，region增大到一定程度会拆分成2个region<br>一个表最终被保存在多个region server里</p>
<p>HMaster 负责元数据信息<br>    1. 表结构信息<br>    2. 表的region分布信息<br>都由hmaster来管理。当hmaster宕机后，对元数据的修改不能做了，比如表结构的更改，region的拆分合并等等</p>
<p>一个region里有多个store，一个store代表一个列族。（region按照行键来划分，所以相当于每一行有几个列族就有几个store）</p>
<p>store包括两部分：内存中的memstore和磁盘的 storefile。写数据会先写到memstore，当数据达到阈值（默认64M）后 region server 会启动 </p>
<blockquote>
<p>storefile 是逻辑概念，hfile 是物理概念</p>
</blockquote>
<p>flushcache 进行将数据写到 storefile 里，每次形成一个storefile。当storefile文件的数量增长到一定阈值后，系统会进行合并（minor、major），在合并过程中会进行版本合并和删除工作（major），形成更大的storefile。当一个region所有storefile的大小和数量超过一定阈值后，会把当前的region分割为两个，并由hmaster分配到相应的regionserver，实现负载均衡</p>
<p>客户端检索数据，先在memstore找，找不到再去blockcache查找，找不到再找storefile，即：client-&gt;memstore-&gt;blockcache-&gt;storefile。如果读到了会把数据放到blockcache里缓存，方便下次读取</p>
<p>Region是HBase中存储和负载均衡的最小单元,不同的Region可以分布在不同的 Region Server上</p>
<p>Region由一个或者多个Store组成，每个store保存一个columns family。每个Strore又由一个memStore和0至多个StoreFile组成</p>
<p>memstore为写入缓存，blockcache为读取缓存</p>
<blockquote>
<p>memstore 是通过 ConcurrentSkipListMap 来实现的</p>
</blockquote>
<p><a href="https://blog.csdn.net/u011598442/article/details/105571034">MemStore的优化</a></p>
<h3 id="2-写数据"><a href="#2-写数据" class="headerlink" title="2. 写数据"></a>2. 写数据</h3><ol>
<li>Client 向 zk 发送请求，请求 meta 表所有的 regionServer</li>
<li>zk 返回 regionServer 地址</li>
<li>Client 获取到 meta 表，请求对应的 region 所在的 regionServer</li>
<li>返回 meta 表数据</li>
<li>Client 向 regionServer 发送写数据请求</li>
<li>写入 wal(write ahead log)</li>
<li>将数据写入 memstore</li>
<li>regionServer 反馈给 Client 写入成功</li>
</ol>
<blockquote>
<p>在 0.9 版本（低版本）时，还存在一个 -ROOT- 表，作用是为了避免meta表过大而拆分为多个子表，可以通过 -ROOT- 表来对meta表进行管理</p>
</blockquote>
<p>第6步和第7步 具体流程如下：</p>
<ul>
<li><p>hbase-server-2.3 版本 搜索 <strong>HRegion</strong> 类，再搜索 <strong>STEP 1</strong>，<code>doMiniBatchMutate(BatchOperation&lt;?&gt; batchOp)</code> 方法即为写数据的部分</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// STEP 1. Try to acquire as many locks as we can and build mini-batch of operations with locked rows =&gt; 写入之前先获取锁</span><br><span class="line"></span><br><span class="line">// STEP 2. Update mini batch of all operations in progress with  LATEST_TIMESTAMP timestamp</span><br><span class="line">// We should record the timestamp only after we have acquired the rowLock,</span><br><span class="line">// otherwise, newer puts/deletes are not guaranteed to have a newer timestamp =&gt; client如果不传时间戳，会自动获取服务器端的时间戳</span><br><span class="line"></span><br><span class="line">// STEP 3. Build WAL edit</span><br><span class="line">// STEP 4. Append the WALEdits to WAL and sync.</span><br><span class="line"></span><br><span class="line">// STEP 5. Write back to memStore</span><br></pre></td></tr></table></figure>
</li>
<li><p>hbase-server-1.3 版本 <code>doMiniBatchMutate(BatchOperation&lt;?&gt; batchOp)</code> 方法不一样。也是先 <code>Build WAL edit</code>，写入日志，但是并没有先同步，而且先写入memstore，在 finally 那里去判断 wal log 是否同步成功，如果不成功，回滚 memstore 记录</p>
</li>
</ul>
<p>写数据时会先向hlog写（方便memstore里的数据丢失后根据hlog恢复，向hlog中写数据的时候也是优先写入内存，后台会有一个线程定期异步刷写数据到hdfs，如果hlog的数据也写入失败，那么数据就会发生丢失）<br>频繁的溢写会导致产生很多的小文件，因此会进行文件的合并，文件在合并的时候有两种方式，minor和major，minor表示小范围文件的合并，major表示将所有的storefile文件都合并成一个</p>
<h3 id="3-Flush-过程"><a href="#3-Flush-过程" class="headerlink" title="3. Flush 过程"></a>3. Flush 过程</h3><p>当写数据到一定程度之后，会把内存中的数据flush到磁盘，配置项在 hbase-default.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">1. hbase.regionserver.global.memstore.size</span><br><span class="line">默认大小为内存大小的0.4。当regionserver的所有的memstore的大小超过这个值的时候，会阻塞客户端的读写</span><br><span class="line">2. hbase.regionserver.global.memstore.size.lower.limit</span><br><span class="line">默认大小为第一个配置项的大小的0.95。即从这个值开始flush到内存，如果写数据过快，超过flush的速度，导致memstore逐渐变大，达到堆大小的0.4，那么就会暂停读写操作，专注于flush，直到memstore的大小下降</span><br><span class="line">3. hbase.regionserver.optionalcacheflushinterval</span><br><span class="line">默认为1个小时（当前内存最后一次编辑时间+1个小时），自动flush到磁盘</span><br><span class="line"></span><br><span class="line">4. hbase.hregion.memstore.flush.size</span><br><span class="line">单个region里memstore大小。默认为128M，超过这个大小就会刷写</span><br><span class="line"></span><br><span class="line">5. hbase.regionserver.max.logs</span><br><span class="line">如果wal的文件数量达到这个值（默认32），就会刷写</span><br><span class="line"></span><br><span class="line">6. hbase.regionserver.hlog.blocksize</span><br><span class="line">默认HDFS 2.x版本默认的blocksize大小</span><br></pre></td></tr></table></figure>

<h3 id="4-读数据"><a href="#4-读数据" class="headerlink" title="4. 读数据"></a>4. 读数据</h3><ol>
<li>Client 向 zk 发送请求，请求 meta 表所有的 regionServer</li>
<li>zk 返回 regionServer 地址</li>
<li>Client 获取到 meta 表，请求对应的 region 所在的 regionServer</li>
<li>返回 meta 表数据</li>
<li>Client 向 regionServer 发送读数据请求</li>
<li>同时会读 memstore 和 storefile，如果 storefile 里有数据，会加载到 blockcache 中，然后把数据做一个合并，取时间戳最大的那条数据返回给client，并且将数据写入到 blockcache</li>
<li>遵循的大体流程是 client-&gt;memstore-&gt;blockcache-&gt;storefile。如果读到了会把数据放到blockcache里缓存，方便下次读取</li>
</ol>
<blockquote>
<p>同时去读内存和磁盘，是为了避免磁盘的时间戳大于内存的时间戳，即put数据的时候设置了老时间戳</p>
</blockquote>
<h3 id="5-compact-合并"><a href="#5-compact-合并" class="headerlink" title="5. compact 合并"></a>5. compact 合并</h3><p>memstore不断flush到磁盘，生成hfile。<br>minor compactions 会把多个文件hfile合并为一个大的hfile<br>major compactions 会把所有hfile合并为一个hfile，默认是7天，但是生产上应该关闭，会非常消耗资源，应在空闲时间手动触发</p>
<blockquote>
<p>compact 会 rewrite hfile to a single storefile 重写的过程会下载hdfs文件，然后重新写入，所以很消耗资源</p>
</blockquote>
<p><code>hbase.hstore.compactionThreshold</code> 是一个store（列族）允许的hfile个数，超过这个个数就会合并</p>
<p>HFile中的每一个keyvalue对象的数据结构分成10段，其中有一个是 keyType，有两个值：put或delete<br>&#x3D;&gt; 所有的增删都是append操作，真正的删除是在hfile做合并的时候，如果数据是在内存中，那么内存中的数据删除是即时的。如果是在两个hfile，那么在hfile做compact的时候会去做删除</p>
<h3 id="6-region-split-切分"><a href="#6-region-split-切分" class="headerlink" title="6. region split 切分"></a>6. region split 切分</h3><p>region 交给不同服务器，缓解热点问题 &#x3D;&gt; hfile 不断拆分，文件越来越大，到最后有可能还是会导致热点问题的存在，因为有的文件特别大，查的数据都在这个文件里 &#x3D;&gt; 建表的时候实现 预分区</p>
<p>HBase 默认分区规则<br>memstore.flush.size&#x3D;128MB<br>max.store.size&#x3D;10G</p>
<p>分区规则：Min(R^2 * “hbase.hregion.memstore.flush.size”, “hbase.hregion.max.filesize”)</p>
<p>第一次拆分大小为：min(10G，11128M)&#x3D;128M &#x2F;&#x2F; 一开始的时候就一个region，当数据量达到128M时，会一分为二，变成2个region，然后会往第二个region里写数据，但是第一个不会写，处于半满状态 &#x3D;&gt; 之前分裂的region都不会再被写入数据，处于半满状态<br>第二次拆分大小为：min(10G，33128M)&#x3D;1152M<br>第三次拆分大小为：min(10G，55128M)&#x3D;3200M<br>第四次拆分大小为：min(10G，77128M)&#x3D;6272M<br>第五次拆分大小为：min(10G，99128M)&#x3D;10G<br>第五次拆分大小为：min(10G，1111128M)&#x3D;10G &#x2F;&#x2F; 最大是10G</p>
<p>官方建议使用一个列族，避免的问题是：有的列族很多数据，有的列族可能只有几条数，按照region切分，然后flush到磁盘，可能会产生很多的小文件</p>
<h3 id="7-LSM"><a href="#7-LSM" class="headerlink" title="7. LSM"></a>7. LSM</h3><p>LSM不是一个具体的树，是一个存储结构或者体系。数据写入是先写入到内存（缓存），满足一定条件后flush到磁盘。为了保住数据不丢失，写入内存之前，先写到log文件中（WAL）。磁盘的顺序写速度要大于随机写的速度。写入到内存中的数据会按照key来进行排序（用到的是 concurrentSkipListMap），这样在flush到hfile的时候就是一个有序的树了。当hfile的个数超过一定个数，为了减少寻址，就会做一次compact。由于结构变成了内存+磁盘，如果内存中没数据，要多读一次磁盘；而写数据则是直接追加即可。所以读要慢一点，写会快一点。</p>
<p>由于这时候内存的数据已经flush到磁盘，那么hlog是不是可以删除？默认hlog最大数量是8，如何知道hlog中的数据其实对应在内存中的数据都已经flush到磁盘？hlog是rs独有的，是rs下的多个region共享的。在往hlog中追加的时候，会写入一个sequenceid，对应的是region级别的一次事务的自增序号（具体应该是针对store）。rs会为每一个region维护一个变量 oldestUnflushedSequenceId （实际是为每一个store），表示这个id前的数据都已经落盘。同时这个 oldestUnflushedSequenceId也会一起被flush到hfile中的元数据里，这样在rs宕机后去按照hlog恢复数据，只需要去读取hfile中的元数据，然后去回放hlog即可。</p>
<h3 id="8-优化"><a href="#8-优化" class="headerlink" title="8. 优化"></a>8. 优化</h3><ol>
<li>预分区</li>
<li>Bulkload 批量插入，通过mr直接生成hfile，导入到hbase表，可能会产生数据不一致，可以重新跑程序，保证数据的最终一致性</li>
<li>rokwey的优化：长度不能太长；唯一；散列 &#x3D;&gt; 期望每个region的负载是一样的，具体体现在如果是扫描少量的数据，尽量在一个region里面，那么就需要是同一个rowkey或者相邻的rowkey；如果是大量的数据，就不能让一个region来处理请求</li>
<li>防止数据倾斜：加盐；时间戳反转；反转部分数据做rowkey</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://mxxct4git.github.io/2020/04/21/Kafka-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/panda-180.png">
      <meta itemprop="name" content="Mxxct">
      <meta itemprop="description" content="君子不器">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="猫熊小才天の书院">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/04/21/Kafka-2/" class="post-title-link" itemprop="url">Kafka进阶</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-21 19:17:00" itemprop="dateCreated datePublished" datetime="2020-04-21T19:17:00+08:00">2020-04-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-19 20:38:19" itemprop="dateModified" datetime="2021-01-19T20:38:19+08:00">2021-01-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/Kafka/" itemprop="url" rel="index"><span itemprop="name">Kafka</span></a>
                </span>
            </span>

          
            <span id="/2020/04/21/Kafka-2/" class="post-meta-item leancloud_visitors" data-flag-title="Kafka进阶" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/04/21/Kafka-2/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/04/21/Kafka-2/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><h3 id="1-知识点"><a href="#1-知识点" class="headerlink" title="1. 知识点"></a>1. 知识点</h3><h4 id="1-1-Kafka不能保证消息的全局有序，只能保证消息在partition内有序"><a href="#1-1-Kafka不能保证消息的全局有序，只能保证消息在partition内有序" class="headerlink" title="1.1 Kafka不能保证消息的全局有序，只能保证消息在partition内有序"></a>1.1 Kafka不能保证消息的全局有序，只能保证消息在partition内有序</h4><h4 id="1-2-每个partition对应于一个log文件，该log文件中存储的就是生产者生成的数据，生产者生成的数据会不断的追加到该log的文件末端，且每条数据都有自己的offset"><a href="#1-2-每个partition对应于一个log文件，该log文件中存储的就是生产者生成的数据，生产者生成的数据会不断的追加到该log的文件末端，且每条数据都有自己的offset" class="headerlink" title="1.2 每个partition对应于一个log文件，该log文件中存储的就是生产者生成的数据，生产者生成的数据会不断的追加到该log的文件末端，且每条数据都有自己的offset"></a>1.2 每个partition对应于一个log文件，该log文件中存储的就是生产者生成的数据，生产者生成的数据会不断的追加到该log的文件末端，且每条数据都有自己的offset</h4><h4 id="1-3-kafka中的分片-索引"><a href="#1-3-kafka中的分片-索引" class="headerlink" title="1.3 kafka中的分片+索引"></a>1.3 kafka中的分片+索引</h4><p>由于生产者生产的消息会不断追加到log文件的末尾，为防止log文件过大导致数据定位效率低下，Kafka采用分片和索引的机制，将每个partition分为多个segment，每个segment对应2个文件—-index文件和log文件，这2个文件位于一个相同的文件夹下，文件夹的命名规则为topic名称+分区序号。也就是partition下有多个segment文件夹，里面都有两个文件–index和log文件。Index文件中存储的数据的索引信息，第一列是offset，第二列是这个数据所对应的log文件中的偏移量。如果要去消费offset为3的数据，首先通过二分法找到数据在哪个index文件中，然后在通过index中offset找到数据在log文件中的offset；这样就可以快速的定位到数据并消费。所以kakfa虽然把数据存储在磁盘中，但是他的读取速度还是非常快的（类似于hbase对于行键来划分region，然后做的索引一样）</p>
<h4 id="1-4-kafka如何保证数据可靠性呢？通过ack来保证。"><a href="#1-4-kafka如何保证数据可靠性呢？通过ack来保证。" class="headerlink" title="1.4 kafka如何保证数据可靠性呢？通过ack来保证。"></a>1.4 kafka如何保证数据可靠性呢？通过ack来保证。</h4><p><img src="https://images.weserv.nl/?url=https://mmbiz.qpic.cn/mmbiz_png/JfTPiahTHJhrm8TXCvosZOiccDGNicKmuQNY7luoaibgofCT7I03m40Ed4fVh0oQsGAJAYiaKERTkDOEVlibxc7LwW5Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1"><br>为保证生产者发送的数据，能可靠的发送到指定的topic，topic的每个partition收到生产者发送的数据后，都需要向生产者发送ack（确认收到），如果生产者收到ack，就会进行下一轮的发送，否则重新发送数据。</p>
<p><img src="https://images.weserv.nl/?url=https://mmbiz.qpic.cn/mmbiz_png/JfTPiahTHJhrm8TXCvosZOiccDGNicKmuQNDQeh5h2rA2hfY6mF9DVXxrjXvicSw7lRsRg5ZatpYoT9YH4hF3FT14g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1"><br>那么kafka什么时候向生产者发送ack？<br>确保follower（就相当于是partition的leader的副本，避免partition的leader挂了，导致无法获取数据）和leader同步完成，leader再发送ack给生产者，这样才能确保leader挂掉之后，能在follower中选举出新的leader后，数据不会丢失。kafka采用的是全部follower都返回ack后由leader发送给生产者。为了避免其中一个follower因为某种故障一直无法同步，leader会维护一个动态的节点列表，对于那些超过一定时间（时间可以自定义）还未返回ack的follower就移除列表。leader故障后，也会从这个列表中来选举新的leader。节点的选择主要是满足两点，一是与leader的网络通信时间应该低时延，二是与leader数据差距，消息条数默认是10000条</p>
<h4 id="1-5-Kafka如何保证消费数据的一致性？通过HW来保证。"><a href="#1-5-Kafka如何保证消费数据的一致性？通过HW来保证。" class="headerlink" title="1.5 Kafka如何保证消费数据的一致性？通过HW来保证。"></a>1.5 Kafka如何保证消费数据的一致性？通过HW来保证。</h4><p>LEO：指每个follower的最大的offset。HW（高水位）：指消费者能见到的最大的offset，LSR队列中最小的LEO，也就是说消费者只能看到1~6的数据，后面的数据看不到，也消费不了。避免leader挂掉后，比如当前消费者消费8这条数据后，leader挂了，此时比如f2成为leader，f2根本就没有9这条数据，那么消费者就会报错，所以设计了HW这个参数，只暴露最少的数据给消费者，避免上面的问题。</p>
<h4 id="1-6-zookeeper在kafka中的作用。"><a href="#1-6-zookeeper在kafka中的作用。" class="headerlink" title="1.6 zookeeper在kafka中的作用。"></a>1.6 zookeeper在kafka中的作用。</h4><p>Kafka集群中有一个broker会被选举为controller，负责管理集群broker的上下线，所有的topic的分区副本分配和leader选举等工作。</p>
<h4 id="1-7-增加分区"><a href="#1-7-增加分区" class="headerlink" title="1.7 增加分区"></a>1.7 增加分区</h4><p><code>./bin/kafka-topics.sh --alter  --zookeeper localhost:2181  --topic 主题名称  --partitions 分区数量 --replication-factor 2</code></p>
<h4 id="1-8-kafka分布式的情况下，如何保证消息的顺序"><a href="#1-8-kafka分布式的情况下，如何保证消息的顺序" class="headerlink" title="1.8 kafka分布式的情况下，如何保证消息的顺序?"></a>1.8 kafka分布式的情况下，如何保证消息的顺序?</h4><p>Kafka 中发送1条消息的时候，可以指定(topic, partition, key) 3个参数。partiton 和 key 是可选的。如果你指定了 partition，那就是所有消息发往同1个 partition，就是有序的。并且在消费端，Kafka 保证，1个 partition 只能被1个 consumer 消费。或者你指定 key（比如 order id），具有同1个 key 的所有消息，会发往同1个 partition。也是有序的。</p>
<h4 id="1-9-kafka-增加分区后，spark-怎么办"><a href="#1-9-kafka-增加分区后，spark-怎么办" class="headerlink" title="1.9 kafka 增加分区后，spark 怎么办"></a>1.9 kafka 增加分区后，spark 怎么办</h4><p>总的解决方案如下：</p>
<ul>
<li>MTDirectKafkaInputDStream继承DirectKafkaInputDStream，override compute方法，在每次生成KafkaRDD时，更新currentOffsets中的分区信息。</li>
<li>在org.apache.spark.streaming.kafka路径下,新建一个KafkaUtils.scala文件，里面的代码直接将spark源码中的KafkaUtils源码复制过来。 修改新建的KafkaUtils.scala，将createDirectStream中new DirectKafkaInputDStream，替换为 new MTDirectKafkaInputDStream.</li>
</ul>
<h3 id="2-进阶"><a href="#2-进阶" class="headerlink" title="2. 进阶"></a>2. 进阶</h3><ol>
<li><p>controller和follower<br>controller会主动去监听zk中的元数据变化，然后同步给follower。broker会尝试去zk中创建目录，谁创建了目录，谁就是controller，follower会监听目录，如果controller挂了，follower会去创建目录，谁创建成功谁就是新的controller &#x3D;&gt; 即所有broker中都存储了kafka集群元数据的信息</p>
</li>
<li><p>每个分区都有3个副本，副本分为leader和follower。leader会负责所有的读写，而follower只是用来同步leader的数据 &#x3D;&gt; 这里的follower可能叫replica更合适</p>
</li>
<li><p>controller kafka的主节点，只是用来同步元数据，副本的leader可以在任何一台broker上</p>
</li>
<li><p>每一个分区都有自己的log日志和index文件，111.log和111.index文件都是成对出现的，其中111指的是当前文件的第一条数据的offset。仿照的是跳表的设计，当查找offset&#x3D;x的数据时，可以快速定位到index文件，index文件内部通过稀松索引，其实也类似于跳表的方式，去定位到offset&#x3D;x的数据的偏移量位置，然后按照偏移量位置去log文件中去遍历去查找</p>
</li>
<li><p>producer端的设计1：消息会封装为 ProducerRecord &#x3D;&gt; 序列化 &#x3D;&gt; 确定partition &#x3D;&gt; 获取集群元数据 &#x3D;&gt; 把数据写到缓冲区，有线程监听缓冲区，然后把数据打包batch上传到broker（16K大小或每100ms）</p>
</li>
<li><p>每一个batch发送完之后都没用了，都在等待gc，如果上传的数据特别多特别快，会导致频繁的gc，最终可能引发full gc。full gc会导致所有的读写都不可用，只会进行gc，执行完gc之后才能继续读写，影响性能</p>
</li>
<li><p>producer端的设计2：将消息的batch仿照线程池的设计，设计一个内存池，将recordbatch每次上传成功后还给内存池。另外有好多batch要发送，如果有需要发送到同一个broker上面，会把这些batch再次封装成一个请求发送</p>
</li>
<li><p>p2p模型，即同一条消息只能被一个消费者消费；发布订阅模型，即允许消息被多个consumer消费。同一个消费组是p2p模型，一个消息只能被一个消费组里的一个消费者消费。不同消费组是订阅模型。一个分区同一时间只能被一个消费组里的一个消费者消费。</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://mxxct4git.github.io/2020/10/20/Flink2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/panda-180.png">
      <meta itemprop="name" content="Mxxct">
      <meta itemprop="description" content="君子不器">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="猫熊小才天の书院">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/10/20/Flink2/" class="post-title-link" itemprop="url">Flink总结</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-10-20 16:20:00" itemprop="dateCreated datePublished" datetime="2020-10-20T16:20:00+08:00">2020-10-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-01-12 17:57:00" itemprop="dateModified" datetime="2021-01-12T17:57:00+08:00">2021-01-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Flink/" itemprop="url" rel="index"><span itemprop="name">Flink</span></a>
                </span>
            </span>

          
            <span id="/2020/10/20/Flink2/" class="post-meta-item leancloud_visitors" data-flag-title="Flink总结" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/10/20/Flink2/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/10/20/Flink2/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Flink总结"><a href="#Flink总结" class="headerlink" title="Flink总结"></a>Flink总结</h2><h3 id="1-状态一致性"><a href="#1-状态一致性" class="headerlink" title="1. 状态一致性"></a>1. 状态一致性</h3><ul>
<li>at most once</li>
<li>at least once</li>
<li>exactly once</li>
</ul>
<h3 id="2-端到端的状态一致性"><a href="#2-端到端的状态一致性" class="headerlink" title="2. 端到端的状态一致性"></a>2. 端到端的状态一致性</h3><ul>
<li>source端（可重设数据的读取位置）<ul>
<li>kafka 可以根据offset回放数据</li>
</ul>
</li>
<li>内部保证（checkpoint）<ul>
<li>每隔一段时间去做一次ck，jobManager会在数据流中加入一个barrier，上游的计算可能有快有慢，如果是精确一次，计算快的算子会把数据先缓存下来，如果是最少一次，那就会加入到计算当中。barrier会广播到下游，所有的task遇到barrier之后都会对自己的状态进行保存，下游收到所有的上游过来的barrier之后，才会进行ck。</li>
<li>同时设置的还有两次ck的时间间隔、允许几个ck存在、超时时间等</li>
<li>ck的保存位置有三种：memory、filesystem、rocksDB。内存中主要是开发测试用，速度快，但是不稳定；放到文件中访问速度快，状态信息不会丢失，但是大小会受到 TaskManager 内存限制（默认是5M），生产可用；rocksDB会先放到数据库，类似于key-value数据存储，当最终ck的时候会放到文件中，缺点是访问的速度下降，但是可以存储大量的状态信息</li>
</ul>
</li>
<li>sink端（从故障恢复时数据不会重复写入外部系统，比如幂等写入，事务写入）<ul>
<li>如果是redis、hbase，通过幂等性，可以保证至少一次 &#x3D;&gt; 精确一次</li>
<li>如果是kafka通过二阶段提交，在sink的时候会先预提交，然后去做ck状态保存，ck失败没关系，因为预提交用户看不到数据；ck成功之后再真正提交，如果这时候提交失败，当flink去做下一次计算的时候会发现commit失败了，会先去进行commit，然后再做计算。</li>
</ul>
</li>
</ul>
<h3 id="3-kafka"><a href="#3-kafka" class="headerlink" title="3. kafka"></a>3. kafka</h3><p>0.8版本kafka：offset是保存在zookeeper中的，但是由于zk不支持高并发，当consumer多了之后，可能会出现问题<br>&#x3D;&gt; 0.10版本kafka：在kafka中有一个 _consumer_offset 的 topic，可以自己去保存</p>
<p>在 FlinkKafkaConsumerBase 类里，有一个 ListState ，即 flink 本身就保存了kafka的offset，然后kafka又有一个topic里保存offset。那么flink默认是使用自己的 ListState，当ck成功之后会去同步到kafka，通过 setCommitOffsetsOnCheckpoints 这个配置来设置是否当ck成功后offset会同步kafka</p>
<h3 id="4-watermark"><a href="#4-watermark" class="headerlink" title="4. watermark"></a>4. watermark</h3><p>通过 assignTimestampsAndWatermarks 方法来设置如何提取事件时间，以及允许的最大乱序时间。默认是周期性每200毫秒生成一次。也可以不要周期性，每来一条数据就尝试获取一次。</p>
<p>当watermark时间大于窗口时间，那么窗口就会被激活，然后进行计算，输出结果。通过 allowLateness() 可以延长窗口被销毁的时间，如果有延迟很久的数据的话，可以再更新窗口</p>
<p>只有当watermark更新了之后，才会去触发 onTimer 定时器</p>
<h3 id="5-savepoint"><a href="#5-savepoint" class="headerlink" title="5. savepoint"></a>5. savepoint</h3><p>相当于重量级的checkpoint，需要用户手动触发，主要用于 作业升级、代码修改等，需要针对每一个算子来设置uid，flink默认的uid生成是根据代码结构，如果uid不一样了就无法获得之前的状态。</p>
<h3 id="6-QueryableState"><a href="#6-QueryableState" class="headerlink" title="6. QueryableState"></a>6. QueryableState</h3><p>每一个状态都保存下来了，然后还需要写入到sink端，如果state是可查询的，那么直接就可以不用写，而把state去当成一个类似数据库一样的东西去使用</p>
<h3 id="7-state类型"><a href="#7-state类型" class="headerlink" title="7. state类型"></a>7. state类型</h3><ul>
<li>Operator State：state是task级别的state，说白了就是每个task对应一个state<ul>
<li>ListState等，一般不使用，比如kafkaconsumer里有一个liststate保存offset partition等信息</li>
</ul>
</li>
<li>KeyedState：主要用前三个<ul>
<li>ValueState</li>
<li>ListState</li>
<li>MapState</li>
<li>ReducingState</li>
<li>AggregatingState</li>
</ul>
</li>
</ul>
<p>使用思路就是</p>
<ol>
<li>不管是open() 方法也好，还是哪个位置，需要先注册，通过 <code>getRuntimeContext().get...(stateDescriptor)</code> 来注册，标明name和其中的类型</li>
<li>在使用的时候，先进行初始化的判断，然后更新，如果是通过定时器的方式来实现的，比如是继承了 processFunction 的方式来实现，那么就需要在 onTimer() 方法中去清空所有的状态</li>
</ol>
<h3 id="8-案例"><a href="#8-案例" class="headerlink" title="8. 案例"></a>8. 案例</h3><h4 id="8-1-热门商品的统计-TopN"><a href="#8-1-热门商品的统计-TopN" class="headerlink" title="8.1 热门商品的统计 TopN"></a>8.1 热门商品的统计 TopN</h4><ol>
<li>设置时间语义和最大乱序时间即watermark</li>
<li>数据进行过滤，然后按照 keyBy(“itemId”).timeWindow(窗口大小，滑动距离).aggerate(窗口增量函数，全窗口函数) 分组后，开滑动窗口，然后去自定义实现 aggerate 方法，增量函数就是一个点击量的累加，即每当来一条数据的时候就会去计算一次，全窗口函数就是对当前窗口内的所有数据去进行一个封装</li>
<li>根据同一窗口的所有数据，再根据窗口时间进行分组，即 keyBy(“windowEnd”).process(new topN(N的大小)) 实现对同一个窗口中的数据进行排序去topN的功能。在 open 方法中去注册一个state，保存窗口内所有输出的数据；在 processElement 方法中每来一条数据，就add进state中，并且去更新定时器，这里的定时器就用当前的窗口时间+1即可 ctx.timeService().registerEventTimer(windowEnd + 1)。flink底层去注册时间戳，是按照时间戳来区分的，如果时间戳一样，那么不管注册多少次，都是一个定时器。在 onTimer() 方法中拿到所有的数据，转换成 arrayList，通过list.sort 方法排序，然后去封装数据</li>
</ol>
<p>保存在listState会存在一定的问题，在处理延迟数据的时候，可能会导致重复数据的输出<br>换成mapState</p>
<h4 id="8-2-dau-uv"><a href="#8-2-dau-uv" class="headerlink" title="8.2 dau&#x2F;uv"></a>8.2 dau&#x2F;uv</h4><p>思路</p>
<ol>
<li><p>按人进行keyby</p>
</li>
<li><p>自定义实现继承 processFunction 方法，在open方法里去初始化两个state，一个是负责浏览次数累加，一个是定时器</p>
</li>
<li><p>在 processElement 方法中初始化定时器，设置为当天的零点，在 onTimer 方法中每当激活了定时器就需要输出</p>
</li>
<li><p>设置时间语义和最大乱序时间即watermark</p>
</li>
<li><p>timewindow定义在1小时，然后实现自定义trigger，每来一条数据处理一次或每20s处理一次，通过布隆过滤器来实现去重。去重不使用set是因为如果数据量很大，会导致内存溢出；然后去实现processFunction，每当一条数据来的时候就会触发process方法，可以去连续redis或者去保存中间的状态</p>
</li>
</ol>
<h3 id="9-定时器"><a href="#9-定时器" class="headerlink" title="9. 定时器"></a>9. 定时器</h3><p>如果要用到延迟处理，一般都需要用到 KeyedProcessFunction。定时器的分类是根据注册的时间戳不同来分类，同一个时间戳，不管注册几次，都是一个定时器。底层通过小顶堆，获取到当前所有时间戳最小的那一个，然后去触发，触发结束后删除，再进行排序</p>
<h3 id="10-窗口"><a href="#10-窗口" class="headerlink" title="10. 窗口"></a>10. 窗口</h3><p>window的属性只有两个，start和end，当数据来了之后，跟wm进行比较，判断在哪一个区间内，然后去激活窗口的process方法做处理。</p>
<p>对于窗口来说，window本身没有意义（两个字段只是划分区间），window里面的中间计算结果才是有意义的（中间的状态保存最重要）</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://mxxct4git.github.io/2020/12/13/DW/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/panda-180.png">
      <meta itemprop="name" content="Mxxct">
      <meta itemprop="description" content="君子不器">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="猫熊小才天の书院">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/13/DW/" class="post-title-link" itemprop="url">数仓架构</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-12-13 11:49:06" itemprop="dateCreated datePublished" datetime="2020-12-13T11:49:06+08:00">2020-12-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-12-16 17:16:14" itemprop="dateModified" datetime="2020-12-16T17:16:14+08:00">2020-12-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DW/" itemprop="url" rel="index"><span itemprop="name">DW</span></a>
                </span>
            </span>

          
            <span id="/2020/12/13/DW/" class="post-meta-item leancloud_visitors" data-flag-title="数仓架构" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/12/13/DW/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/12/13/DW/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="数仓架构"><a href="#数仓架构" class="headerlink" title="数仓架构"></a>数仓架构</h2><h3 id="1-数据仓库"><a href="#1-数据仓库" class="headerlink" title="1. 数据仓库"></a>1. 数据仓库</h3><p>特点：</p>
<ol>
<li>面向主题<blockquote>
<p>电商，流量，交易。。。</p>
</blockquote>
</li>
<li>集成<blockquote>
<p>各个数据源：数据库，日志，爬虫。。。</p>
</blockquote>
</li>
<li>相对稳定<blockquote>
<p>主要用来查询，不是用来删除和修改</p>
</blockquote>
</li>
<li>反映历史变化<blockquote>
<p>N年的记录，每个月、每个季度、每年的汇总记录</p>
</blockquote>
</li>
<li>管理决策<blockquote>
<p>分析数据 -&gt; 指标</p>
</blockquote>
</li>
</ol>
<blockquote>
<p>数据湖指的是所有的原始数据，数据仓库指经过处理的原始数据（四层）</p>
</blockquote>
<h3 id="2-数据库和数据仓库的区别"><a href="#2-数据库和数据仓库的区别" class="headerlink" title="2. 数据库和数据仓库的区别"></a>2. 数据库和数据仓库的区别</h3><p>数据库： 联机事务处理和查询处理 OLTP<br>传统的数据仓库：主要是查询，用结果来支撑决策。联机分析处理 OLAP<br>大数据数据仓库：基于Hadoop的海量 分布式数据仓库<br>实时仓库：Flink + Kafka&#x2F;Redis&#x2F;HBase</p>
<h3 id="3-架构"><a href="#3-架构" class="headerlink" title="3. 架构"></a>3. 架构</h3><p>lambda：实时+ 数仓<br>kappa：实时<br>批流一体</p>
<h3 id="4-数仓分层"><a href="#4-数仓分层" class="headerlink" title="4. 数仓分层"></a>4. 数仓分层</h3><h4 id="4-1-分层"><a href="#4-1-分层" class="headerlink" title="4.1 分层"></a>4.1 分层</h4><ol>
<li>ODS(Operation Data Store)：原始数据</li>
<li>DWD(Data Warehouse Detail)：对原始数据进行清洗（去除空值、脏数据、超过极限范围的数据）、脱敏等，保存明细数据<ul>
<li>选择业务过程 -&gt; 声明粒度 -&gt; 确认维度 —&gt; 确认事实</li>
</ul>
</li>
<li>DWS(Data Warehouse Service)：按天进行轻度汇总，比如一个用户一天下单次数</li>
<li>DWT(Data Warehouse Topic)：对数据进行累计汇总，比如一个用户从注册那天开始至今一共下了多少次单</li>
<li>ADS(Application Data Store)：为各种统计报表提供数据</li>
</ol>
<blockquote>
<p>第3、4层不一定都有，甚至都没有，直接从第2层经过操作到第5层，中间没有保留中间表<br>并不能保证一定按照这个分层来进行。如果说过滤条件也比较少，甚至可以直接从ODS进行过滤后直接返回给用户。</p>
</blockquote>
<h4 id="4-2-为什么要分层"><a href="#4-2-为什么要分层" class="headerlink" title="4.2 为什么要分层"></a>4.2 为什么要分层</h4><ol>
<li>把复杂问题简单化：拆解每一个需求，方便定位问题</li>
<li>减少重复开发：提供模型的复用性</li>
<li>隔离原始数据：使真实数据和汇总数据解耦</li>
</ol>
<h3 id="5-数据集市和数据仓库的区别"><a href="#5-数据集市和数据仓库的区别" class="headerlink" title="5. 数据集市和数据仓库的区别"></a>5. 数据集市和数据仓库的区别</h3><p>数据集市是一个微型的数据仓库，通常有更少的数据，更少的主题区域，以及更少的历史数据，是部门级的。<br>数据仓库是企业级的。</p>
<h3 id="6-数据理论"><a href="#6-数据理论" class="headerlink" title="6. 数据理论"></a>6. 数据理论</h3><h4 id="6-1-范式"><a href="#6-1-范式" class="headerlink" title="6.1 范式"></a>6.1 范式</h4><ol>
<li>定义：范式可以理解为设计一张数据表的表结构</li>
<li>优点：降低数据的冗余性；数据保存多份，一次修改，需要修改多个表，很难保证数据的<strong>一致性</strong></li>
<li>缺点：获取数据的时候，需要通过Join连接来获取最后的数据</li>
<li>分类：<ol>
<li>第一范式：属性不可分割</li>
<li>第二范式：不能存在非主键字段<strong>部分函数依赖</strong>主键字段，可以消除部分数据冗余</li>
<li>第三范式：不能存在非主键字段<strong>传递函数依赖</strong>主键字段</li>
<li>BCNF、第四范式、第五范式。。。</li>
</ol>
</li>
</ol>
<blockquote>
<p>满足的范式越多，数据冗余性越低，但是表会越散，影响查询效率</p>
</blockquote>
<ol start="5">
<li>函数依赖：完全函数依赖、部分函数依赖、传递函数依赖</li>
</ol>
<h4 id="6-2-OLTP-和-OLAP"><a href="#6-2-OLTP-和-OLAP" class="headerlink" title="6.2 OLTP 和 OLAP"></a>6.2 OLTP 和 OLAP</h4><ul>
<li>OLTP：传统数据库的主要应用，主要是基本的、日常的事务处理，比如银行交易</li>
<li>OLAP：数据仓库的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观的查询结果</li>
</ul>
<blockquote>
<p>OLTP 一般是关系建模方式，OLAP 一般是维度建模方式</p>
</blockquote>
<h4 id="6-3-关系建模和维度建模"><a href="#6-3-关系建模和维度建模" class="headerlink" title="6.3 关系建模和维度建模"></a>6.3 关系建模和维度建模</h4><p>关系建模符合3NF，表松散，表的数据量多，但是数据冗余性低。由于数据分布在很多的表中，这些数据可以更为灵活地被应用，功能性更强。</p>
<p>维度建模：基于维度和度量。维度就是事实，相当于用户进行的业务操作</p>
<h4 id="6-4-维度表和事实表"><a href="#6-4-维度表和事实表" class="headerlink" title="6.4 维度表和事实表"></a>6.4 维度表和事实表</h4><p>维度表：一般是对事实的描述信息，例如：用户、商品、日期、地区等<br>特征：维度表的范围很宽（具有多个属性，列比较多）；跟事实表相比，行数较小；内容比较固定，比如编码表</p>
<p>事实表：对应着业务事件，每一个业务都应该有一个事实表。<strong>事实</strong>对应了业务事件中的<strong>度量值</strong>。<br>特征：行数很多；内容相对的窄，列数较少（维度外键 + 度量值）；经常发生变化</p>
<p>事实表又分为如下三种：</p>
<ol>
<li>事务型事实表<ul>
<li>以每个事务或事件为单位，一旦插入就不会再作修改，更新方式就只能是增量方式</li>
</ul>
</li>
<li>周期型快照事实表<ul>
<li>不会保留所有数据，只保留固定时间间隔的数据</li>
<li>事务型事实表用来保存所有的数据。比如购物车数据，不需要记录每一次加减，只要汇总每一天最后的那个状态就行。</li>
</ul>
</li>
<li>累积型快照事实表<ul>
<li>用于跟踪业务事实的变化。</li>
</ul>
</li>
</ol>
<blockquote>
<p>这三种像是针对关系型数据库如何设计表来说的，根据表类型的不同，来决定每天同步数据到数仓的方式是全量还是增量。<br>比如第一种因为只会新增数据，所以每天增量同步到数仓即可；第二种需要全量同步；第三种将新增变化数据同步之后，还需要再做一步整合。</p>
</blockquote>
<blockquote>
<p>事实表一般是动词，维度表一般是名词。</p>
</blockquote>
<h3 id="7-星型模型、雪花模型、星座模型"><a href="#7-星型模型、雪花模型、星座模型" class="headerlink" title="7. 星型模型、雪花模型、星座模型"></a>7. 星型模型、雪花模型、星座模型</h3><p>雪花模型和星型模型的区别主要是在维度的层级，标准的星型模型维度只有一层，雪花模型可能会涉及多层。<br>多个事实表可能会使用相同的维度表，组合起来就是星座模型。</p>
<h3 id="Q-A"><a href="#Q-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h3><p>数仓最重要的是什么？<br>数据的准确性。数仓最终是为了支撑决策，决策的前提要保证数据的准确性。</p>
<p>如何保证数据的准确性？<br>元数据的建设与管理是其中重要的一个环节。元数据建设的目标是打通数据接入到加工 ，再到数据消费整个链路，规范元数据体系与模型，提供统一的元数据服务出口，保障元数据产出的稳定性和质量。首先梳理清楚元仓底层数据，对元数据做分类，如计算元数据、存储元数据、质量元数据等，减少数据重复建设，保障数据的唯一性。<br>另外， 要丰富表和字段使用说明，方便使用和理解。根据元仓底层数据构建元仓中间层，建设元数据基础宽表，也就是元数据中间层，打通从数据产生到消费整个链路。<br>也可在粒度、规范等方面展开，见仁见智。</p>
<p>如何做数据治理？数据资产管理呢？<br>在明确数据治理是数据管理的一部分之后，下一个问题就是定义数据管理。治理相对容易界定，它是用来明确相关角色、工作责任和工作流程的，确保数据资产能长期有序地、可持续地得到管理。<br>而数据管理则是一个更为广泛的定义，它与任何时间采集和应用数据的可重复流程的方方面面都紧密相关。<br>其实在数仓的整个链路中数据治理的理念是渗入其中的，在ETL过程中开发人员会对数据清洗这其实就是治理的一部分，再加上后期数据资产的管理和落定都有数据治理的渗入。</p>
<p>如何控制数据质量？<br>1.数据质量保证原则：完整性，准确性，数据质量，及时性，一致性<br>2.数据质量方法：数据资产等级的划定<br>3.数据加工过程卡点校验<br>4.风险点监控：针对在线或者离线数据的监控<br>5.质量衡量：故障等级的划定以及数据质量的事件的记录</p>
<p>元数据的理解？元数据管理系统？<br>元数据主要记录数据仓库中模型的定义、各层级间的映射关系、监控数据仓库的数据状态及 ETL 的任务运行状态。<br>元数据有重要的应用价值，是数据管理、数据内容、数据应用的基础，在数据管理方面为集团数据提供在计算、存储、成本、质量、安全、模型等治理领域上的数据支持。<br>元数据管理系统： 首先梳理清楚元仓底层数据，对元数据做分类，如计算元数据、存储元数据、质量元数据等，减少数据重复建设，保障数据的唯一性。<br>另外， 要丰富表和字段使用说明，方便使用和理解。根据元仓底层数据构建元仓中间层，建设元数据基础宽表，也就是元数据中间层，打通从数据产生到消费整个链路</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://mxxct4git.github.io/2020/12/09/Java-4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/panda-180.png">
      <meta itemprop="name" content="Mxxct">
      <meta itemprop="description" content="君子不器">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="猫熊小才天の书院">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/09/Java-4/" class="post-title-link" itemprop="url">Java 容器</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-12-09 14:22:23" itemprop="dateCreated datePublished" datetime="2020-12-09T14:22:23+08:00">2020-12-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-12-12 17:47:23" itemprop="dateModified" datetime="2020-12-12T17:47:23+08:00">2020-12-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/Collection/" itemprop="url" rel="index"><span itemprop="name">Collection</span></a>
                </span>
            </span>

          
            <span id="/2020/12/09/Java-4/" class="post-meta-item leancloud_visitors" data-flag-title="Java 容器" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/12/09/Java-4/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2020/12/09/Java-4/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Java-容器"><a href="#Java-容器" class="headerlink" title="Java 容器"></a>Java 容器</h2><ul>
<li>Collection<ul>
<li>List：可以重复<ul>
<li>CopyOnWriteArrayList</li>
<li>Vector</li>
<li>ArrayList</li>
<li>LinkedList</li>
</ul>
</li>
<li>Set：不可重复<ul>
<li>HashSet &amp; LinkedHashSet：HashSet无序，哈希表；LinkedHashSet 通过链表可以实现有序</li>
<li>SortedSet &amp; TreeSet：有序，红黑树</li>
<li>EnumSet</li>
<li>CopyOnWriteArraySet</li>
<li>ConcurrentSkipListSet</li>
</ul>
</li>
<li>Queue：主要是针对多线程 JUC<ul>
<li>Deque：双端队列<ul>
<li>ArrayDeque 实现类</li>
<li>LinkedList 实现类</li>
<li>BlockingDeque 接口 JUC重点</li>
</ul>
</li>
<li><strong>BlockingQueue</strong>：阻塞队列<ul>
<li>ArrayBlockingQueue</li>
<li>PriorityBlockingQueue</li>
<li>LinkedBlockingQueue</li>
<li>TransferQueue &amp; LinkedTransferQueue：有一定容量，但是一个生产者放进去一个值，如果没消费者来消费，就会一直在等待</li>
<li>SynchronousQueue：容量为空，必须放进去一个值才能拿，也必须拿走了才能继续生产。和LinkedTransferQueue的区别就是SynchronousQueue没有容量</li>
<li>Delayqueue</li>
</ul>
</li>
<li>PriorityQueue：小顶堆或大顶堆（具体是什么堆，通过自定义comparator），只拿最上面的那一个。由于底层实现是堆（即二叉树）实现的，所以并不能保证线程同步。如果要支持并发，需要用PriorityBlockingQueue。</li>
<li>ConcurrentLinkedQueue</li>
<li>DelayQueue</li>
</ul>
</li>
</ul>
</li>
<li>Map<ul>
<li>HashMap &amp; LinkedHashMap</li>
<li>TreeMap</li>
<li>WeakHashMap</li>
<li>IdentityHashMap</li>
<li><strong>ConcurrentHashMap</strong></li>
<li>ConcurrentSkipListMap</li>
</ul>
</li>
</ul>
<p>为什么没有 ConcurrentTreeMap？因为树上锁的话一般就需要锁一整棵树，影响效率；同时对树进行修改，如果底层是红黑树，修改数据可能导致整棵树的转换。<br>ConcurrentHashMap 无法保证顺序，如果要高并发+顺序，可以使用 ConcurrentSkipListMap</p>
<p>CAS和Synchronized的效率比较:</p>
<ol>
<li>Synchronized的过程：无锁 -&gt; 偏向锁 -&gt; 自旋锁 -&gt; 重量锁</li>
<li>如果线程不是很多，或者执行操作的时间不是很长的时候，cas可能会好一点</li>
</ol>
<p>vector 和 arraylist 相似，都是动态数组，但是两者有不同</p>
<ol>
<li>vector 里面方法全是 synchronized 的</li>
<li>vector 包含了很多传统的方法，这些方法不属于集合框架</li>
</ol>
<p>ArrayList 不带锁，如果要带锁的话，<code>Collections.SynchronizedList(list)</code> 返回的就是加了锁的list，这个集合类方法会在所有操作上加一个 synchronized<br>LinkedList 不带锁，如果要带锁的话，<code>Collections.SynchronizedList(list)</code> 返回的就是加了锁的list<br>ArrayList 和 LinkedList 的区别：</p>
<ol>
<li>ArrayList 底层是数组实现，LinkedList 底层是双向链表实现</li>
<li>ArrayList 查询快；LinkedList 增删快 &#x3D;&gt; 原因是数组增删要移动数据，链表查询要移动指针</li>
</ol>
<blockquote>
<p>存储形式：<br>顺序存储 数组 查询快，增删慢<br>链式存储 链表 查询慢，增删快<br>散列存储 哈希 数组+链表 查询和增删很快 </p>
</blockquote>
<p>HashMap、LinkedHashMap 和 Treemap 的区别：</p>
<ol>
<li><p>HashMap 无序；LinkedHashMap 通过链表维护Key的插入顺序；TreeMap 通过红黑树来维护Key的自然顺序或者自定义顺序，但不是插入顺序。</p>
<blockquote>
<p>HashTable 不允许key或value为空；put get 方法都加上了synchronized，线程同步，性能较低。如果要用线程同步的HashMap可以用 ConcurrentHashMap</p>
</blockquote>
</li>
<li><p>HashMap 底层是 数组+链表，链表长度大于8的时候，转成红黑树；LinkedHashMap 比HashMap 多维护一个双向链表，可以按照插入顺序从头部或尾部迭代；</p>
<blockquote>
<p>LinkedHashMap 在HashMap 的基础上进行拓展，数组不变，链表增加了before和after，也就是将所有的kv（不论在数组的哪一个槽位）都通过前后指针连了起来。<br>LinkedHashMap 通过accessOrder 来决定是按照插入顺序还是访问顺序，accessOrder &#x3D; true，会调用 afterNodeAccess() 方法，HashMap也调用了不过是空方法，LinkedHashMap 通过这个方法将访问的节点也就是kv放到链表的最后。另外在accessOrder &#x3D; true的模式下，迭代LinkedHashMap的同时去查询数据，会导致fail-fast，因为afterNodeAccess()会修改modCount，迭代的顺序已经改变。<br>LinkedHashMap 重写了 containsValue()，HashMap 是双循环去遍历，而因为kv都通过双链表关联起来了，LinkedHashMap 可以通过直接通过head遍历链表；containsKey() 还是用的 HashMap 的，直接通过hashcode来遍历。</p>
</blockquote>
</li>
<li><p>HashMap 和 LinkedHashMap 的操作时间复杂度在O(1)，TreeMap 是红黑树，时间复杂度在O(logn)</p>
</li>
</ol>
<p>HashSet 、TreeSet 和 LinkedHashSet 的区别：</p>
<ol>
<li><p>HashSet 无序，基于HashMap来实现；LinkedHashSet 有序， 基于 LinkedHashMap 来实现的。</p>
</li>
<li><p>TreeSet 是 SortedSet 接口的唯一实现类（NavigableSet 接口继承 SortedSet 接口，TreeSet 实现 NavigableSet 接口），通过comparator方法来实现有序。在底层实现上，是通过Treemap的结构，也就是红黑树来实现存储。TreeSet 不允许存放null值。放入的对象必须实现HashCode()方法，放入的对象，是以hashcode作为标识的，而具有相同内容的string对象，hashcode是一样的。</p>
</li>
<li><p>Set 集合要求存储的元素比较重写hashcode和equals方法。比如HashSet的存放时，会先用hashcode来找位置，然后用equals来判断是否重复。</p>
<blockquote>
<p>&#x3D;&#x3D; 判断的是内存中的地址，equals 比较内存中存放的值是否相等</p>
</blockquote>
</li>
</ol>
<p>CopyOnWriteArrayList：在JUC包下面，基于写时复制，并发的读，当需要修改的(add、set、remove)时候，加锁，先复制整个容器，修改元素，将原容器的引用指向新的容器。适合读多写少。</p>
<blockquote>
<p>copyonwrite的思想应该和redis在持久化实现的过程是一致的，即并发读，当需要修改的时候，只把需要修改的那部分复制出来进行修改，然后把引用的指针指向新的内容。这个类在实现copyonwrite的时候是复制整个容器。</p>
</blockquote>
<p>CopyOnWriteArraySet：底层用的也是 CopyOnWriteArrayList 类，在add、remove修改的时候需要加锁，复制整个容器</p>
<p>Queue 接口</p>
<table>
<thead>
<tr>
<th></th>
<th>引发异常</th>
<th align="left">返回特殊值</th>
</tr>
</thead>
<tbody><tr>
<td>插入</td>
<td>add（如果不能插入抛出异常）</td>
<td align="left">offer（不超过容量的情况下插入，如果无法插入的话返回false）。在容量受限的队列中，offer要优于add</td>
</tr>
<tr>
<td>移除头部元素</td>
<td>remove（如果队列为空，返回NoSuchElementException异常）</td>
<td align="left">poll（如果队列为空，返回false）</td>
</tr>
<tr>
<td>返回头部数据</td>
<td>element（如果队列为空，返回NoSuchElementException异常）</td>
<td align="left">peek（如果队列为空，返回null）</td>
</tr>
</tbody></table>
<p>Deque：继承Queue接口，双端队列，允许头部或尾部进行操作</p>
<blockquote>
<p>LinkedList 也实现了这个接口方法，add 是直接在链表的尾部加入，还可以从头部加入，addfirst或者offerfirst</p>
</blockquote>
<p>ArrayDeque：实现Deque接口，是一个双向数组，或者叫循环数组。普通数组下标0是第一个元素，下标最大的是最后一个元素，在最后进行操作还可以，但是如果在头部进行操作，就需要移动所有的数据下标，而ArrayDeque通过循环数组就解决了这个问题。具体是通过移动head和tail的下标来实现。计算个数的时候通过位运算获得<code>return (tail - head) &amp; (elements.length - 1);</code>每当add数据的时候，都会判断head是否等于tail，如果是的话就扩容，所以head&#x3D;tail只会出现在初始化的时候。</p>
<p><img src="https://images.weserv.nl/?url=https://img-blog.csdn.net/20160413143417742"></p>
<p><a href="https://mxxct4git.github.io/2020/08/11/Thread-2/"><strong>BlockingQueue</strong> 同步队列中的堵塞队列</a></p>
<p><strong>BlockingQueue</strong>：阻塞队列</p>
<p>注意事项：</p>
<ol>
<li>不接受null元素</li>
<li>可以限定容量</li>
<li>主要用于实现 生产者消费者 队列，但它另外还支持 Collection 接口</li>
<li>线程安全</li>
</ol>
<blockquote>
<p>公平锁和非公平锁：公平锁即一个线程组里能保证每个线程都拿到锁，那么这个锁就是公平锁。如果保证不了每个线程都拿到锁，即存在有线程饿死，那么这个锁就是非公平锁。ReentrantLock 默认是非公平锁。<br>比如：t1获取锁，t2等待，t1释放，t2正准备获取t3插队，t3获取锁，t2继续等待。这就是非公平锁，可能会因为线程抢占问题而导致某个线程一直在等待。如果是公平锁的话，t3会发现等待队列有人，就不会随意抢占了。</p>
</blockquote>
<p>ArrayBlockingQueue：基于数组，有界，初始化时限定容量，不会扩容。生产和消费公用一个锁，即两者不会真正并行。可以设置锁是否公平。<br>PriorityBlockingQueue：基于优先级（优先级的判断通过构造函数传入的Compator对象来决定），无界阻塞队列。生产和消费公用一个锁，即两者不会真正并行。不会阻塞生产者，统一使用的是offer()，由于队列是无界的，会一直放进去数据；但是消费的时候如果队列为空，会一直等待。如果生产者速度远大于消费者，某一刻会导致OOM。<br>LinkedBlockingQueue：基于链表，如果不指定容量，默认是Integer.MAX_VALUE，相当于无界，为了避免内存问题一般指定容量。内部有takeLock和putLock，保证了生产和消费可以并行执行，并且都是非公平锁。<a href="https://blog.csdn.net/tonywu1992/article/details/83419448">LinkedBlockingQueue</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">// Removes a node from head of queue.</span><br><span class="line">private E dequeue() &#123;</span><br><span class="line">  // assert takeLock.isHeldByCurrentThread();</span><br><span class="line">  // assert head.item == null;</span><br><span class="line">  Node&lt;E&gt; h = head;</span><br><span class="line">  Node&lt;E&gt; first = h.next;</span><br><span class="line">  h.next = h; // help GC</span><br><span class="line">  head = first;</span><br><span class="line">  E x = first.item;</span><br><span class="line">  first.item = null;</span><br><span class="line">	return x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>TransferQueue &amp; LinkedTransferQueue：无界。transfer() 方法将元素给消费者，如果没有消费者就会堵塞生产者；tryTransfer() 将元素立刻给一个消费者，如果没有消费者就返回false，不会将元素放入队列，还可以指定等待时间。<a href="https://www.cnblogs.com/lighten/p/7505355.html">LinkedTransferQueue</a><br>SynchronousQueue：容量为空，必须放进去一个值才能拿，也必须拿走了才能继续生产。和LinkedTransferQueue的区别就是SynchronousQueue没有容量<br>DelayQueue：无界。元素只有当指定的延迟时间到了，才能从里面获取到元素。即不会堵塞生产者，但是会堵塞消费者。使用场景比如用来管理一个超时未响应的连接队列。<br>ConcurrentLinkedQueue：通过CAS来实现</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/26/">26</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Mxxct"
      src="/images/panda-180.png">
  <p class="site-author-name" itemprop="name">Mxxct</p>
  <div class="site-description" itemprop="description">君子不器</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">127</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">61</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">69</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/mxxt" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;mxxt" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:386965035@qq.com" title="邮箱 → mailto:386965035@qq.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>邮箱</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2018 – 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Mxxct</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>















  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : true,
      notify     : true,
      appId      : 'FeVPpNOBXhL1P240cNkmAKc3-gzGzoHsz',
      appKey     : 'TJ9vKn2xQ16geSxRr80seK0S',
      placeholder: "来说点什么吧~~~",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
